import os
import asyncio
import aiohttp
from datetime import datetime
import pytz
from telegram import Bot
import translators as ts
import re
from transformers import pipeline
import torch

# é…ç½®ä¿¡æ¯
API_BASE_URL = "https://api.pearktrue.cn/api/dailyhot/"
NEWS_API_URL = "https://newsapi.org/v2/top-headlines"
NEWS_API_KEY = os.environ["NEWS_API_KEY"]

PLATFROMS = [
    ["å“”å“©å“”å“©", "mobileUrl"], ["å¾®åš", "url"],
    ["ç™¾åº¦è´´å§", "url"], ["å°‘æ•°æ´¾", "url"],
    ["ITä¹‹å®¶", "url"], ["è…¾è®¯æ–°é—»", "url"],
    ["ä»Šæ—¥å¤´æ¡", "url"], ["36æ°ª", "url"],
    ["æ¾æ¹ƒæ–°é—»", "url"], ["ç™¾åº¦", "url"],
    ["ç¨€åœŸæ˜é‡‘", "mobileUrl"], ["çŸ¥ä¹", "url"]
]

FOREIGN_MEDIA = [
    ["å½­åšç¤¾", "bloomberg"], # ["BBC", "bbc-news"]
]

CATEGORIES = [
    # ["ä¸–ç•Œ-å•†ä¸š", "business"], ["ä¸–ç•Œ-ç§‘å­¦", "science"], ["ä¸–ç•Œ-æŠ€æœ¯", "technology"], ["ä¸–ç•Œ-ç»¼åˆ", "general"]
]

TELEGRAM_BOT_TOKEN = os.environ["BOT_TOKEN"]
TELEGRAM_CHANNEL_ID = '@tech_news_aggregation'

# åˆ†ç±»é¢‘é“æ˜ å°„
CATEGORY_CHANNELS = {
    "ç§‘æŠ€": "@tech_news_aggregation",
    "è´¢ç»": "@finance_news_aggregation",
    "å¨±ä¹": "@entertainment_news_aggregation",
    "ç¤¾ä¼š": "@society_news_aggregation",
    "å›½é™…": "@world_news_aggregation"
}

categories = ["ç§‘æŠ€", "è´¢ç»", "å¨±ä¹", "ç¤¾ä¼š", "å›½é™…", "å…¶ä»–"]  # å®šä¹‰åˆ†ç±»ç±»åˆ«

bot = Bot(token=TELEGRAM_BOT_TOKEN)
# _ = ts.preaccelerate_and_speedtest()

classifier = pipeline("zero-shot-classification", 
                     model="MoritzLaurer/mDeBERTa-v3-base-mnli-xnli",
                     device="cuda" if torch.cuda.is_available() else "cpu")

# æ›´ç»†åŒ–çš„ä¸­æ–‡åˆ†ç±»ç±»åˆ«
CATEGORIES = [
    "ç§‘æŠ€", "è´¢ç»", "å¨±ä¹", "ç¤¾ä¼š", "å›½é™…", 
    "ä½“è‚²", "å¥åº·", "æ•™è‚²", "å†›äº‹", "æ±½è½¦"
]

# æ·»åŠ ç±»åˆ«æè¿°æé«˜å‡†ç¡®åº¦
CATEGORY_DESCRIPTIONS = {
    "ç§‘æŠ€": "åŒ…æ‹¬äº’è”ç½‘ã€äººå·¥æ™ºèƒ½ã€ç”µå­äº§å“ã€è½¯ä»¶å¼€å‘ç­‰æŠ€æœ¯ç›¸å…³å†…å®¹",
    "è´¢ç»": "æ¶‰åŠè‚¡ç¥¨ã€é‡‘èã€æŠ•èµ„ã€ç»æµæ”¿ç­–ã€å¸‚åœºè¶‹åŠ¿ç­‰å†…å®¹",
    "å¨±ä¹": "æ¶µç›–æ˜æ˜Ÿã€ç”µå½±ã€ç”µè§†å‰§ã€éŸ³ä¹ã€ç»¼è‰ºèŠ‚ç›®ç­‰å¨±ä¹äº§ä¸šå†…å®¹",
    "ç¤¾ä¼š": "å…³äºæ°‘ç”Ÿã€æ³•å¾‹ã€å…¬å…±äº‹ä»¶ã€ç¤¾ä¼šç°è±¡ç­‰ç¤¾ä¼šç”Ÿæ´»å†…å®¹",
    "å›½é™…": "å›½é™…å…³ç³»ã€å¤–äº¤æ”¿ç­–ã€å…¨çƒäº‹ä»¶ç­‰è·¨å›½å†…å®¹",
    "ä½“è‚²": "ä½“è‚²èµ›äº‹ã€è¿åŠ¨å‘˜ã€ä½“è‚²äº§ä¸šç›¸å…³å†…å®¹",
    "å¥åº·": "åŒ»ç–—ã€å…»ç”Ÿã€ç–¾ç—…é¢„é˜²ã€å¥åº·ç”Ÿæ´»æ–¹å¼ç­‰å†…å®¹",
    "æ•™è‚²": "å­¦æ ¡æ•™è‚²ã€æ•™è‚²æ”¹é©ã€è€ƒè¯•æ”¿ç­–ã€å­¦æœ¯ç ”ç©¶ç­‰å†…å®¹",
    "å†›äº‹": "å›½é˜²ã€æ­¦å™¨è£…å¤‡ã€å†›äº‹è¡ŒåŠ¨ã€å†›äº‹ç§‘æŠ€ç­‰å†…å®¹",
    "æ±½è½¦": "æ±½è½¦è¡Œä¸šã€æ–°è½¦å‘å¸ƒã€æ±½è½¦æŠ€æœ¯ã€è½¦å±•ç­‰å†…å®¹"
}

async def classify_text(text, categories):
    """ä¼˜åŒ–åçš„ä¸­æ–‡æ–‡æœ¬åˆ†ç±»å‡½æ•°"""
    if not text or len(text) < 3:
        return None
    
    # é¢„å¤„ç†æ–‡æœ¬
    processed_text = preprocess_text(text)
    
    # å‡†å¤‡å¸¦æœ‰æè¿°çš„æ ‡ç­¾
    candidate_labels = [f"{cat}: {CATEGORY_DESCRIPTIONS.get(cat, '')}" for cat in categories]
    
    try:
        result = classifier(
            processed_text, 
            candidate_labels, 
            multi_label=False,
            hypothesis_template="è¿™ä¸ªæ–‡æœ¬å…³äº{}"  # ä¸­æ–‡ä¼˜åŒ–æ¨¡æ¿
        )
        
        # æå–æœ€å¯èƒ½çš„ç±»åˆ«
        best_label = result["labels"][0].split(":")[0]
        confidence = result["scores"][0]
        
        # åªè¿”å›ç½®ä¿¡åº¦é«˜äºé˜ˆå€¼çš„åˆ†ç±»
        return best_label if confidence > 0.6 else "å…¶ä»–"
    except Exception as e:
        print(f"åˆ†ç±»é”™è¯¯: {str(e)}")
        return None

def preprocess_text(text):
    """é¢„å¤„ç†æ–‡æœ¬ä»¥æé«˜åˆ†ç±»å‡†ç¡®åº¦"""
    if not text:
        return ""
    
    # ç§»é™¤URLã€ç‰¹æ®Šå­—ç¬¦å’Œå¤šä½™ç©ºæ ¼
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'\@\w+|\#', '', text)
    text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)  # ä¿ç•™ä¸­æ–‡å’ŒåŸºæœ¬å­—ç¬¦
    text = re.sub(r'\s+', ' ', text).strip()
    
    # æˆªæ–­è¿‡é•¿çš„æ–‡æœ¬(æ¨¡å‹æœ‰tokené™åˆ¶)
    return text[:500]

def escape_html(text):
    if text is None:
        return ""
    return text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")

async def fetch_data(url, params):
    """å¼‚æ­¥è·å–æ•°æ®"""
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(url, params=params, timeout=10) as response:
                response.raise_for_status()
                data = await response.json()
                return data
        except Exception as e:
            print(f"é”™è¯¯ï¼šè¯·æ±‚æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{str(e)}")
            return None

async def fetch_hot_data(platform):
    """è·å–æŒ‡å®šå¹³å°çš„çƒ­æœæ•°æ®"""
    url = f"{API_BASE_URL}?title={platform}"
    data = await fetch_data(url, {})
    if data and data.get("code") == 200:
        return data.get("data", [])
    print(f"è­¦å‘Šï¼š{platform} APIè¿”å›é”™è¯¯ï¼š{data.get('message') if data else 'æœªçŸ¥é”™è¯¯'}")
    return []

async def fetch_news_data(source=None, category=None):
    """è·å–æŒ‡å®šæ¥æºæˆ–ç±»åˆ«çš„æ–°é—»æ•°æ®"""
    params = {'apiKey': NEWS_API_KEY, 'pageSize': 20}
    if source:
        params['sources'] = source
    if category:
        params['category'] = category
    data = await fetch_data(NEWS_API_URL, params)
    if data and data.get("status") == "ok":
        print(data)
        return data.get("articles", [])
    print(f"è­¦å‘Šï¼š{source or category} APIè¿”å›é”™è¯¯ï¼š{data.get('message') if data else 'æœªçŸ¥é”™è¯¯'}")
    return []

async def translate_text(text):
    """ä½¿ç”¨ translators ç¿»è¯‘æ–‡æœ¬"""
    if text is None:
        return ""
    try:
        translated_text = ts.translate_text(text, translator='caiyun', from_language='en', to_language='zh')
        await asyncio.sleep(2)
        return translated_text
    except Exception as e:
        print(f"ç¿»è¯‘é”™è¯¯ï¼š{text}ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{str(e)}")
        return text

async def format_and_classify_data(data_list, url_key, is_news=False):
    """æ ¼å¼åŒ–æ•°æ®å¹¶è¿›è¡Œåˆ†ç±»"""
    classified_data = {category: [] for category in categories}

    for index, item in enumerate(data_list[:30], start=1):
        # åŸå§‹æ ¼å¼åŒ–é€»è¾‘
        title = item.get('title', 'æ— æ ‡é¢˜') if not is_news else await translate_text(item.get('title', 'æ— æ ‡é¢˜'))
        title = title if title is not None else 'æ— æ ‡é¢˜'
        title = escape_html(title)
        url = item.get(url_key, '#')
        hot_info = f"<i>{item.get('hot')}ğŸ”¥</i>" if not is_news and item.get('hot') else ""

        if item.get('description'):
            desc = await translate_text(item.get('description'))
        elif item.get('desc'):
            desc = item.get('desc')
        else:
            desc = ''

        if desc:
            desc = desc.replace('\n', '')
            if len(desc) > 150:
                desc = desc[:100] + 'â€¦â€¦'
            desc = "\n\n" + escape_html(desc) 
        else:
            desc = ""

        formatted_string = f"{index}. <a href=\"{url}\">{title}</a>{hot_info}{desc}"

        # åˆ†ç±»é€»è¾‘
        text_to_classify = f"{title} {desc}"
        category = await classify_text(text_to_classify, categories)

        if not category:  # åˆ†ç±»å¤±è´¥é»˜è®¤ç±»åˆ«
            category = "ç¤¾ä¼š" if not is_news else "å›½é™…"

        classified_data[category].append(formatted_string)

    return classified_data

async def send_classified_data(platform, classified_data, is_news=False):
    """æŒ‰åˆ†ç±»å‘é€æ•°æ®åˆ°ä¸åŒé¢‘é“"""
    # 1. å‘é€åŸå§‹èšåˆæ•°æ®åˆ°ä¸»é¢‘é“
    all_items = []
    for category in classified_data:
        all_items.extend(classified_data[category][:5])  # æ¯ä¸ªåˆ†ç±»å–å‰5æ¡

    if all_items:
        message = f"<b>{escape_html(platform)} çƒ­ç‚¹ç²¾é€‰</b>\n\n" + "\n\n".join(all_items[:15])
        await bot.send_message(chat_id=TELEGRAM_CHANNEL_ID, text=message, parse_mode='HTML')
        await asyncio.sleep(2)

    # 2. å‘é€å®Œæ•´åˆ†ç±»æ•°æ®åˆ°å„ä¸“ä¸šé¢‘é“
    for category, items in classified_data.items():
        if items and category in CATEGORY_CHANNELS:
            channel_id = CATEGORY_CHANNELS[category]
            header = "ğŸ“° " if is_news else "ğŸ”¥ "
            message = f"{header}<b>{escape_html(platform)} - {category}ç²¾é€‰</b>\n\n" + "\n\n".join(items[:15])
            try:
                await bot.send_message(chat_id=channel_id, text=message, parse_mode='HTML')
                await asyncio.sleep(1)
            except Exception as e:
                print(f"å‘é€åˆ°{channel_id}å¤±è´¥: {str(e)}")

async def main():
    tz = pytz.timezone('Asia/Shanghai')
    current_time = datetime.now(tz).strftime("%Y-%m-%d %H:%M")
    init_message = await bot.send_message(chat_id=TELEGRAM_CHANNEL_ID, text=f"åŒ—äº¬æ—¶é—´: <b>{current_time}</b>", parse_mode='HTML')
    await bot.pin_chat_message(chat_id=TELEGRAM_CHANNEL_ID, message_id=init_message.message_id)
    await asyncio.sleep(2)

    all_message_info = []

    for platform in PLATFROMS:
        print(f"æ­£åœ¨è·å–ï¼š{platform[0]}")
        data = await fetch_hot_data(platform[0])
        if data:
            classified = await format_and_classify_data(data, platform[1])
            await send_classified_data(platform[0], classified)
        await asyncio.sleep(2)

    for media in FOREIGN_MEDIA:
        print(f"æ­£åœ¨è·å–ï¼š{media[0]}")
        articles = await fetch_news_data(source=media[1])
        if articles:
            classified = await format_and_classify_data(articles, 'url', is_news=True)
            await send_classified_data(media[0], classified, is_news=True)
        await asyncio.sleep(2)

if __name__ == '__main__':
    asyncio.run(main())